#! /usr/bin/python

from termcolor import colored
import argparse
import difflib
import os
import progressbar
import re
import shutil
import subprocess
import tarfile
import tempfile
import urllib2


def download_upstream(version, tmp_dir):
  filename = 'postgresql-%s.tar.gz' % version
  tar_path = os.path.join(tmp_dir, filename)
  url = ('https://ftp.postgresql.org/pub/source/v%(version)s/'
         'postgresql-%(version)s.tar.gz' % {'version': args.version})

  print 'Downloading %s to %s...' % (url, tar_path)

  req = urllib2.urlopen(url)

  if (req.getcode() != 200):
    raise Exception('Failed to download Postgres tarball! Got status code %d.'
                    % req.getcode())

  size = int(req.info()['Content-Length'])
  progress = progressbar.ProgressBar().start()

  with open(tar_path, 'wb') as f:
    blk_sz = 8192
    count = 0
    while True:
      chunk = req.read(blk_sz)
      if not chunk:
        break
      f.write(chunk)
      count += 1
      if size > 0:
        percent = min(int(count * blk_sz * 100.0 / size), 100)
        progress.update(percent)

  progress.finish()
  print 'Download complete.'
  return tar_path


def safe_mkdirs(path):
  try:
    os.makedirs(path)
  except OSError:
    # Directory already exists
    pass


def list_files(path):
  dirs = os.walk(path)
  regex = re.compile('^%s/?' % path)
  files = []

  for _dir, _, filenames in dirs:
    _dir = regex.sub('', _dir)

    # Ignore any git internal files
    if _dir.startswith('.git'):
      continue

    # Ignore any py or unit test files.
    if _dir.startswith('src/test/py') or _dir.startswith('src/test/unit'):
      continue

    # Ignore any PipelineDB files.
    if (_dir.startswith('bin') or
        _dir.startswith('pkg') or
        _dir.startswith('src/bin/pipeline') or
        _dir.startswith('src/bin/recv-alerts') or
        _dir.startswith('src/backend/pipeline') or
        _dir.startswith('src/include/pipeline') or
        _dir.startswith('src/test/unit') or
        _dir.startswith('src/test/py')):
      continue

    # Ignore any PipelineDB test files.
    if (_dir.startswith('src/test/regress/sql') or
        _dir.startswith('src/test/regress/expected')):
        filenames = filter(lambda f: not f.startswith('cont_'), filenames)

    # Ignore dot files and emacs temp files or compiled files.
    filenames = filter(lambda f: not f.startswith('.') and not f.endswith('~')
                       and not f.endswith('.o'),
                       filenames)

    files.extend(map(lambda f: os.path.join(_dir, f).rstrip('/'), filenames))

  return set(files)


def is_path_useful(path):
  """
  All paths that belong to documentation files are considered useless.
  """
  return not (path.startswith('doc/') or path.endswith('.po'))


def main(args):
  """
  This script works as follows:

  1) Download the upstream source tarball for the given version of Postgres
  2) Overwrite all files that we haven't modified with the newer version
     from the upstream source tarball
  3) Mercilessly override all files in the doc/ directory and all files with
     .po extension.
  4) For all new files in the upstream branch copy them as is to the repo
     directory and store their paths in ./added_files.txt.
  5) For all files removed in the upstream branch, store their paths in
     ./removed_files.txt.
  3) For all mismatching files, generate a diff against the
     corresponding upstream file in the downloaded source tarball.
     Save this file to ./diffs. We also put a copy of the upstream
     source file in ./diffs because it's useful to have when manually
     merging. A list of all these files is stored in ./mismatch_files.txt.
  """
  with open(os.devnull, 'w') as dnull:
    subprocess.call(['make', 'clean'], stdout=dnull)

  tmp_dir = args.tmp_dir or tempfile.mkdtemp()
  safe_mkdirs(tmp_dir)
  tar_path = download_upstream(args.version, tmp_dir)

  tar = tarfile.open(tar_path)
  tar.extractall(path=tmp_dir)
  tar.close()

  upstream_root = os.path.join(tmp_dir, 'postgresql-%s' % (args.version))
  assert os.path.exists(upstream_root) and os.path.isdir(upstream_root)
  local_root = os.curdir

  diff_dir = os.path.join(os.curdir, 'diffs')
  safe_mkdirs(diff_dir)

  upstream_files = list_files(upstream_root)
  local_files = list_files(local_root)

  # Are there any new files in the upstream branch?
  added_files = sorted(filter(is_path_useful, upstream_files - local_files))
  if added_files:
    log_file = os.path.join(local_root, 'added_files.txt')
    print 'There are %d new files! Storing paths in %s.' % (len(added_files),
                                                            log_file)
    with open(log_file, 'w+') as f:
      f.write('\n'.join(added_files))

  # Are there any deleted files in the local branch?
  rm_files = sorted(filter(is_path_useful, local_files - upstream_files))
  if rm_files:
    log_file = os.path.join(local_root, 'removed_files.txt')
    print 'There are %d removed files! Storing paths in %s.' % (len(rm_files),
                                                                log_file)
    with open(log_file, 'w+') as f:
      f.write('\n'.join(rm_files))

  # Go through all files in the upstream branch and add, overwrite or generate
  # diffs as necessary.
  print 'Generating diffs against upstream files for mismatching files...'
  need_merge = []
  progress = progressbar.ProgressBar()
  completed = 0
  default_action = 'c'
  for rel_path in progress(upstream_files):
    completed += 1
    upstream_path = os.path.join(upstream_root, rel_path)
    local_path = os.path.join(local_root, rel_path)

    # File missing in local? Copy it.
    if not os.path.exists(local_path):
      subdir, _ = os.path.split(local_path)
      safe_mkdirs(subdir)
      shutil.copyfile(upstream_path, local_path)
      continue

    # Overwrite any not useful files.
    if not is_path_useful(rel_path):
      shutil.copyfile(upstream_path, local_path)
      continue

    lf = open(local_path)
    rf = open(upstream_path)

    # We both potentially modified this file.
    left = [l.strip('\n') for l in lf.readlines()]
    right = [l.strip('\n') for l in rf.readlines()]

    lf.close()
    rf.close()

    contains_pdb = False
    for line in left:
      if 'pipelinedb' in line.lower():
        contains_pdb = True
        break

    if not contains_pdb:
      shutil.copyfile(upstream_path, local_path)
      continue

    diff_lines = list(difflib.unified_diff(left, right,
                                           local_path, upstream_path))

    # No difference? Overwrite.
    if not diff_lines:
      shutil.copyfile(upstream_path, local_path)
      continue

    diff_path = os.path.join(diff_dir, rel_path) + '.diff'
    subdir, _ = os.path.split(diff_path)
    safe_mkdirs(subdir)

    # Give the option to simply clobber the local copy as this is a common case
    print
    print '=' * 80
    print local_path
    print '=' * 80
    print

    for line in diff_lines:
      if re.match('\-[^\-]', line):
        print colored(line, 'red')
      elif re.match('\+[^\+]', line):
        print colored(line, 'green')
      else:
        print line

    print
    print '=' * 80
    print local_path
    print '=' * 80
    print

    while True:
      action = raw_input('(c)lobber, (k)eep or (m)anual merge? [%s] (%d/%d): ' % (default_action, completed, len(upstream_files)))
      if not action:
        action = default_action
      if action in ['c', 'k', 'm']:
        break
    default_action = action

    if action == 'c':
      shutil.copyfile(upstream_path, local_path)
      continue
    if action == 'k':
      continue

    with open(diff_path, 'w+') as f:
      f.write('\n'.join(diff_lines))

    need_merge.append(local_path)

    # It's also useful when merging to have the original copy
    # of upstream file, so save it as well
    upstream_copy_path = os.path.join(diff_dir, rel_path)
    shutil.copyfile(upstream_path, upstream_copy_path)

  # It's useful to have a list of all files written to diffs/
  # so we can check off files as we merge them
  mismatch_files = os.path.join(local_root, 'mismatch_files.txt')
  with open(mismatch_files, 'w+') as f:
    f.write('\n'.join(sorted(need_merge)))
    print ('There are %d mismatching files! Storing paths in %s.' %
           (len(need_merge), mismatch_files))

  shutil.rmtree(tmp_dir)
  print 'Cleaned up %s.' % tmp_dir


if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument('--upstream-version', action='store', dest='version',
                      required=True, help='Upstream version to diff against')
  parser.add_argument('--tmp-dir', action='store', dest='tmp_dir',
                      required=False, help='Temporary directory to store '
                      'upstream source tree in')
  args = parser.parse_args()
  main(args)
